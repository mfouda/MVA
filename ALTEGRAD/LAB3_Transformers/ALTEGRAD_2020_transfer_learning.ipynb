{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ALTEGRAD_2020_transfer_learning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlAfI8mCWAf3"
      },
      "source": [
        "# Transfer learning for NLP\n",
        "## ALTEGRAD - Lab session 3\n",
        "#### Moussa Kamal Eddine, Hadi Abdine (Dascim LIX)\n",
        "##### November 2020"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqukuIe0Rb_c"
      },
      "source": [
        "import math\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FF6fjkqgN39"
      },
      "source": [
        "### The Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0cj9WkSFQwl"
      },
      "source": [
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self, ntoken, nhead, nhid, nlayers, dropout=0.5):\n",
        "        super(TransformerModel, self).__init__()\n",
        "        '''\n",
        "        ntokens: the size of vocabulary\n",
        "        nhid: the hidden dimension of the model.\n",
        "        We assume that embedding_dim = nhid\n",
        "        nlayers: the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
        "        nhead: the number of heads in the multiheadattention models\n",
        "        dropout: the dropout value\n",
        "         '''\n",
        "        self.model_type = \"Transformer\"\n",
        "        self.encoder = nn.Embedding(ntoken,nhid) # fill me, nhid = the dim_embed\n",
        "        self.pos_encoder = PositionalEncoding(nhid,dropout) #fill me, the PositionalEncoding class is implemented in the next cell\n",
        "        encoder_layers = nn.TransformerEncoderLayer(nhid,nhead,nhid,dropout) #fill me we assume nhid = d_model = dim_feedforward\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers,nlayers) #fill me\n",
        "        self.nhid = nhid\n",
        "        self.init_weights()\n",
        "\n",
        "    def generate_square_subsequent_mask(self, sz):\n",
        "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
        "        mask = (\n",
        "            mask.float()\n",
        "            .masked_fill(mask == 0, float(\"-inf\"))\n",
        "            .masked_fill(mask == 1, float(0.0))\n",
        "        )\n",
        "        return mask\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.1\n",
        "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    def forward(self, src, src_mask):\n",
        "        src = self.encoder(src) * math.sqrt(self.nhid) \n",
        "        src = self.pos_encoder(src)#fill me\n",
        "        output = self.transformer_encoder(src, src_mask)\n",
        "        return output\n",
        "\n",
        "\n",
        "class ClassificationHead(nn.Module):\n",
        "    def __init__(self, nhid, nclasses):\n",
        "        super(ClassificationHead, self).__init__()\n",
        "        self.decoder = nn.Linear(nhid,nclasses)#fill me)\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.1\n",
        "        self.decoder.bias.data.zero_()\n",
        "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    def forward(self, src):\n",
        "        output = self.decoder(src)\n",
        "        return output\n",
        "    \n",
        "class Model(nn.Module):\n",
        "    def __init__(self, ntoken, nhead, nhid, nlayers, nclasses, dropout=0.5):\n",
        "        super(Model, self).__init__()\n",
        "        self.base = TransformerModel(ntoken, nhead, nhid, nlayers, dropout=0.5)#fill me\n",
        "        self.classifier = ClassificationHead(nhid,nclasses)#fill me \n",
        "\n",
        "    def forward(self, src, src_mask):\n",
        "        # base model\n",
        "        x = self.base(src,src_mask)#fill me\n",
        "        # classifier model\n",
        "        output = self.classifier(x)#fill me\n",
        "        return output"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kt2QQohaFZry"
      },
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, nhid, dropout=0.1, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        pe = torch.zeros(max_len, nhid)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(\n",
        "            torch.arange(0, nhid, 2).float() * (-math.log(10000.0) / nhid)\n",
        "        )\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer(\"pe\", pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[: x.size(0), :]\n",
        "        return self.dropout(x)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfEYHJx2JW6l"
      },
      "source": [
        "Let's verify if our model works, by applying one inference step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhb2gkUhJMR0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f7f615d-c60f-4f71-c767-3f5e510f81ba"
      },
      "source": [
        "ntokens = 100 #fill me # the size of vocabulary\n",
        "nhid = 200  # hidden dimension\n",
        "nlayers = 4  # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
        "nhead = 2  # the number of heads in the multiheadattention models\n",
        "dropout = 0  # the dropout value\n",
        "\n",
        "model = Model(ntokens, nhead, nhid, nlayers, ntokens, dropout).to(device)\n",
        "dummy_input = torch.tensor([[2, 6, 2, 5, 43, 21]]).to(device)\n",
        "src_mask = model.base.generate_square_subsequent_mask(1).to(device)\n",
        "out = model.forward(dummy_input, src_mask)\n",
        "\n",
        "print(out.shape) # is it the right shape?"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 6, 100])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i74NN897Fcit"
      },
      "source": [
        "## Vocabulary and Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qjd26ghWuff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d90ac582-d682-44e2-d299-4c2492006709"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/dict.txt\n",
        "!head -5 dict.txt"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-04 15:09:36--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/dict.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 577587 (564K) [text/plain]\n",
            "Saving to: ‘dict.txt’\n",
            "\n",
            "dict.txt            100%[===================>] 564.05K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2020-12-04 15:09:36 (18.2 MB/s) - ‘dict.txt’ saved [577587/577587]\n",
            "\n",
            "▁d 1\n",
            "es 1\n",
            "▁l 1\n",
            "en 1\n",
            "on 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFdH_-JeFbGA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a909cb7a-0f58-41d1-ac36-ce24ec0ee58a"
      },
      "source": [
        "path_vocab = \"dict.txt\"\n",
        "token2ind = {\"<sos>\": 0, \"<pad>\": 1, \"<eos>\": 2, \"<oov>\": 3} # the 4 first indices are reserved to special tokens\n",
        "with open(path_vocab, \"r\") as f:\n",
        "    for idx, line in enumerate(f):\n",
        "        word = line.split()[0].strip()\n",
        "        token2ind[word] = idx+4 #fill me\n",
        "\n",
        "ind2token = dict(zip(token2ind.values(),token2ind.keys()))\n",
        "\n",
        "print(ind2token[1111])"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "▁trop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOExGODajN8p"
      },
      "source": [
        "### Data Loader\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0jN-Ar9i5Q1"
      },
      "source": [
        "import numpy\n",
        "import torch\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "\n",
        "class Dataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        path_documents,\n",
        "        path_labels=None,\n",
        "        token2ind={},\n",
        "        max_len=512,\n",
        "        task=\"language_modeling\",\n",
        "    ):\n",
        "        self.task = task\n",
        "        self.max_len = max_len\n",
        "        self.token2ind = token2ind\n",
        "        self.documents = []\n",
        "        self.labels = []\n",
        "        with open(path_documents, \"r\") as f1:\n",
        "            for line in f1:\n",
        "                self.documents.append(line.strip())\n",
        "        if task == \"classification\":\n",
        "            with open(path_labels, \"r\") as f1:\n",
        "                for line in f1:\n",
        "                    self.labels.append(int(line.strip()))\n",
        "            assert len(self.labels) == len(self.documents)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.documents)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        sequence = self.documents[index].split()\n",
        "        if len(sequence) > self.max_len - 1:\n",
        "            sequence = sequence[: self.max_len - 1]\n",
        "        source_sequence = [self.token2ind[\"<sos>\"]] + [\n",
        "            self.token2ind[word] if word in self.token2ind else self.token2ind[\"<oov>\"]\n",
        "            for word in sequence[: self.max_len]\n",
        "        ]\n",
        "        if self.task == \"language_modeling\":\n",
        "            target = source_sequence[1:]\n",
        "            target.append(self.token2ind[\"<eos>\"])\n",
        "        elif self.task == \"classification\":\n",
        "            target = [self.labels[index]]\n",
        "        sample = {\n",
        "            \"source_sequence\": torch.tensor(source_sequence),\n",
        "            \"target\": torch.tensor(target),\n",
        "        }\n",
        "        return sample\n",
        "\n",
        "\n",
        "def MyCollator(batch):\n",
        "    source_sequences = pad_sequence(\n",
        "        #we use padding to match the length of the sequences in the same batch\n",
        "        [sample[\"source_sequence\"] for sample in batch], padding_value=token2ind[\"<pad>\"]\n",
        "    )\n",
        "    target = pad_sequence(\n",
        "        [sample[\"target\"] for sample in batch], padding_value=token2ind[\"<pad>\"]\n",
        "    )\n",
        "    return source_sequences, target.reshape(-1)\n",
        "\n",
        "\n",
        "def get_loader(\n",
        "    path_documents,\n",
        "    path_labels=None,\n",
        "    token2ind={},\n",
        "    max_len=512,\n",
        "    batch_size=32,\n",
        "    task=\"language_modeling\",\n",
        "):\n",
        "    dataset = Dataset(\n",
        "        path_documents,\n",
        "        path_labels=path_labels,\n",
        "        token2ind=token2ind,\n",
        "        max_len=512,\n",
        "        task=task,\n",
        "    )\n",
        "    data_loader = DataLoader(\n",
        "        dataset=dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        collate_fn=MyCollator,\n",
        "        pin_memory=True,\n",
        "        drop_last=True,\n",
        "    )\n",
        "    return data_loader"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTns4lHrjUTa"
      },
      "source": [
        "## The Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_jwosiLjRsS"
      },
      "source": [
        "def train(\n",
        "    path_data_train,\n",
        "    path_labels_train=None,\n",
        "    path_data_valid=None,\n",
        "    save_interval=-1,\n",
        "    log_interval=5,\n",
        "    task=\"language_modeling\",\n",
        "    batch_size=32,\n",
        "):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    ntokens = len(token2ind)\n",
        "    data_loader = get_loader(\n",
        "        path_data_train,\n",
        "        path_labels_train,\n",
        "        token2ind,\n",
        "        task=task,\n",
        "        batch_size=batch_size,\n",
        "    )\n",
        "    \n",
        "    losses = []\n",
        "    for idx, data in enumerate(data_loader): #step 1\n",
        "        optimizer.zero_grad()\n",
        "        src_mask = model.base.generate_square_subsequent_mask(data[0].size(0)).to(\n",
        "            device\n",
        "        )\n",
        "        input = data[0].to(device)\n",
        "        output = model(input, src_mask) #step 2\n",
        "        if task == 'classification':\n",
        "            #last vector only\n",
        "            \n",
        "            output = output[-1]#fill me  ##### WATCHOUT FOR ERRORS\n",
        "\n",
        "            # output shape before reshape == torch.Size([190, 8, 2])\n",
        "            # output shape after reshape == torch.Size([8, 2])\n",
        "            # target shape== torch.Size([8])\n",
        "                \n",
        "\n",
        "\n",
        "        output = output.view(-1, output.shape[-1])\n",
        "        target =  data[1] #fill me ## maybe will need a reshape\n",
        "        target = target.to(device)\n",
        "\n",
        "     \n",
        "        loss =  criterion(output,target) #fill me, Cross entropy check next cells\n",
        "        #fill me step 3\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5) # prevent exploding gradient \n",
        "        #fill me step 4\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item() \n",
        "        if idx % log_interval == 0 and idx > 0:\n",
        "            cur_loss = total_loss / log_interval\n",
        "            print(\n",
        "                \"| epoch {:3d} | {:5d}/{:5d} steps | \"\n",
        "                \"loss {:5.5f} | ppl {:8.3f}\".format(\n",
        "                    epoch, idx, len(data_loader), cur_loss, math.exp(cur_loss),\n",
        "                )\n",
        "            )\n",
        "            losses.append(cur_loss)\n",
        "            total_loss = 0\n",
        "    return losses"
      ],
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgf6BDB9jUr6"
      },
      "source": [
        "ntokens = len(ind2token) #fill me # the size of vocabulary\n",
        "nhid = 200  # the dimension of the feedforward network model in nn.TransformerEncoder\n",
        "nlayers = 4  # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
        "nhead = 2  # the number of heads in the multiheadattention models\n",
        "dropout = 0  # the dropout value\n",
        "\n",
        "nclasses = 2 # for classification task only\n",
        "\n",
        "model = Model(ntokens, nhead, nhid, nlayers, ntokens, dropout).to(device)"
      ],
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-OLy4KIkDwf"
      },
      "source": [
        "# optimization paramerters\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=token2ind['<pad>'])\n",
        "lr = 0.0003  # learning rate\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
      ],
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bwh3n9xZQy4e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71b8ebd5-adb1-43e6-e7b8-0e778ffebc97"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/pretraining_subset.txt\n",
        "path_data_train = \"pretraining_subset.txt\""
      ],
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-04 20:06:38--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/pretraining_subset.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10146460 (9.7M) [text/plain]\n",
            "Saving to: ‘pretraining_subset.txt.5’\n",
            "\n",
            "pretraining_subset. 100%[===================>]   9.68M  56.3MB/s    in 0.2s    \n",
            "\n",
            "2020-12-04 20:06:39 (56.3 MB/s) - ‘pretraining_subset.txt.5’ saved [10146460/10146460]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0m11g4ScjZaR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54d46399-1ac8-451f-8044-1575e05bb841"
      },
      "source": [
        "#pretraining on a tiny subset\n",
        "log_interval = 500\n",
        "epochs = 2\n",
        "for epoch in range(1, epochs + 1): #5\n",
        "    train(\n",
        "        path_data_train,\n",
        "        save_interval=-1,\n",
        "        task=\"language_modeling\",\n",
        "        batch_size=16,\n",
        "        log_interval=log_interval,\n",
        "    )"
      ],
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "| epoch   1 |   500/ 3125 steps | loss 7.73123 | ppl 2278.406\n",
            "| epoch   1 |  1000/ 3125 steps | loss 7.02145 | ppl 1120.413\n",
            "| epoch   1 |  1500/ 3125 steps | loss 6.77792 | ppl  878.242\n",
            "| epoch   1 |  2000/ 3125 steps | loss 6.60763 | ppl  740.728\n",
            "| epoch   1 |  2500/ 3125 steps | loss 6.46353 | ppl  641.321\n",
            "| epoch   1 |  3000/ 3125 steps | loss 6.37475 | ppl  586.837\n",
            "| epoch   2 |   500/ 3125 steps | loss 6.18118 | ppl  483.562\n",
            "| epoch   2 |  1000/ 3125 steps | loss 6.09614 | ppl  444.140\n",
            "| epoch   2 |  1500/ 3125 steps | loss 6.07966 | ppl  436.879\n",
            "| epoch   2 |  2000/ 3125 steps | loss 6.04549 | ppl  422.203\n",
            "| epoch   2 |  2500/ 3125 steps | loss 5.99158 | ppl  400.047\n",
            "| epoch   2 |  3000/ 3125 steps | loss 5.96887 | ppl  391.063\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MeOM1dOvkO4e"
      },
      "source": [
        "## Text Generation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BcBC6FSkMH3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "680ec824-462f-433f-a131-c6925fddd3f4"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/pretrained_model_4layers.pt\n",
        "\n",
        "model = Model(ntokens, nhead, nhid, nlayers, ntokens).to(device)\n",
        "\n",
        "#load the checkpoint\n",
        "checkpoint = torch.load('pretrained_model_4layers.pt') \n",
        "#load state dict\n",
        "model.load_state_dict(checkpoint['model_state_dict']) "
      ],
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-04 20:10:42--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/pretrained_model_4layers.pt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 88093955 (84M) [application/octet-stream]\n",
            "Saving to: ‘pretrained_model_4layers.pt.5’\n",
            "\n",
            "pretrained_model_4l 100%[===================>]  84.01M   183MB/s    in 0.5s    \n",
            "\n",
            "2020-12-04 20:10:43 (183 MB/s) - ‘pretrained_model_4layers.pt.5’ saved [88093955/88093955]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBRRVsWqlIoQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2540ccdc-2ce7-4074-e513-8b85688ec9c1"
      },
      "source": [
        "!pip install sentencepiece\n",
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/sentencepiece.french.model\n",
        "\n",
        "import sentencepiece as spm\n",
        "\n",
        "s = spm.SentencePieceProcessor(model_file='sentencepiece.french.model') #load sentencepiece model\n",
        "\n",
        "#examples\n",
        "encoded = s.encode_as_pieces(\"Bonjour les amis!\")\n",
        "decoded = s.decode_pieces(encoded)\n",
        "print(encoded)\n",
        "print(decoded)"
      ],
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (0.1.94)\n",
            "--2020-12-04 20:10:46--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/sentencepiece.french.model\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115362 (1.1M) [application/octet-stream]\n",
            "Saving to: ‘sentencepiece.french.model.4’\n",
            "\n",
            "sentencepiece.frenc 100%[===================>]   1.06M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2020-12-04 20:10:46 (29.1 MB/s) - ‘sentencepiece.french.model.4’ saved [1115362/1115362]\n",
            "\n",
            "['▁Bonjour', '▁les', '▁amis', '!']\n",
            "Bonjour les amis!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtLlV05pkQI3"
      },
      "source": [
        "def infer_next_token(sent):\n",
        "    model.eval()\n",
        "    sent_pieces = s.encode_as_pieces(sent)\n",
        "    source = [token2ind['<sos>']] + [token2ind[el] for el in sent_pieces]\n",
        "    source = torch.tensor(source).to(device)\n",
        "    source = source.reshape(-1, 1)\n",
        "    src_mask = model.base.generate_square_subsequent_mask(source.size(0)).to(device)\n",
        "    out = model(source, src_mask)\n",
        "    next_token_ind = out[-1].argmax(-1)\n",
        "    return next_token_ind, out\n",
        "    \n",
        "def infer_next_tokens(sent, max_len=50):\n",
        "    # to be implemented\n",
        "    i=0\n",
        "\n",
        "    while i <= max_len:\n",
        "\n",
        "      next_token_ind,_ = infer_next_token(sent)\n",
        "\n",
        "      next_word = ind2token[int(next_token_ind.cpu().detach().numpy())]\n",
        "      sent += next_word\n",
        "      i+=1\n",
        "      if next_word == '<eos>':\n",
        "        break\n",
        "    \n",
        "    print(sent)"
      ],
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f83Nn5nSly4v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4307b624-9eaf-4ada-ebae-d35712e36415"
      },
      "source": [
        "sent = \"Bonjour les\"\n",
        "infer_next_tokens(sent)"
      ],
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bonjour les▁gens▁qui▁ont▁été▁très▁accueillants▁et▁sympathiques.<eos>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lp7mjVzomoZ3"
      },
      "source": [
        "### Supervised task"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0K1BZsblmEmx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed801997-d564-4019-ab0d-c031d0f6f27c"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/train.review.spm\n",
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/train.label\n",
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/test.review.spm\n",
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/test.label\n",
        "\n",
        "path_data_train = \"train.review.spm\"\n",
        "path_labels_train = \"train.label\"\n",
        "\n",
        "path_data_valid = \"test.review.spm\"\n",
        "path_labels_valid = \"test.label\""
      ],
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-04 20:10:46--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/train.review.spm\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1495960 (1.4M) [text/plain]\n",
            "Saving to: ‘train.review.spm.3’\n",
            "\n",
            "train.review.spm.3  100%[===================>]   1.43M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2020-12-04 20:10:46 (26.2 MB/s) - ‘train.review.spm.3’ saved [1495960/1495960]\n",
            "\n",
            "--2020-12-04 20:10:46--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/train.label\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3200 (3.1K) [text/plain]\n",
            "Saving to: ‘train.label.3’\n",
            "\n",
            "train.label.3       100%[===================>]   3.12K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-12-04 20:10:47 (71.6 MB/s) - ‘train.label.3’ saved [3200/3200]\n",
            "\n",
            "--2020-12-04 20:10:47--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/test.review.spm\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1864544 (1.8M) [text/plain]\n",
            "Saving to: ‘test.review.spm.3’\n",
            "\n",
            "test.review.spm.3   100%[===================>]   1.78M  --.-KB/s    in 0.03s   \n",
            "\n",
            "2020-12-04 20:10:47 (51.0 MB/s) - ‘test.review.spm.3’ saved [1864544/1864544]\n",
            "\n",
            "--2020-12-04 20:10:47--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/test.label\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4000 (3.9K) [text/plain]\n",
            "Saving to: ‘test.label.3’\n",
            "\n",
            "test.label.3        100%[===================>]   3.91K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-12-04 20:10:47 (26.3 MB/s) - ‘test.label.3’ saved [4000/4000]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MLfvjiom2SL"
      },
      "source": [
        "# a function to evaluate the validation accuracy of the model.\n",
        "def evaluate_accuracy(data_loader):\n",
        "    #to be implemented\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for data in data_loader:\n",
        "\n",
        "      src = data[0].to(device)\n",
        "      src_mask = model.base.generate_square_subsequent_mask(data[0].size(0)).to(device)\n",
        "      targets = data[1].to(device)\n",
        "\n",
        "      outputs = model(src,src_mask)\n",
        "\n",
        "\n",
        "      \n",
        "      _, predictions = torch.max(outputs.data[-1], 1)\n",
        "\n",
        "      correct += (predictions == targets).sum().item()\n",
        "\n",
        "      total += targets.size(0)\n",
        "      \n",
        "\n",
        "    print('your accuracy is ',correct/total)\n",
        "    return correct/total\n",
        "    "
      ],
      "execution_count": 190,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzmx7T7xoa6v"
      },
      "source": [
        "#save the base model to be loaded later in the fine-tuning phase\n",
        "torch.save({\"model_state_dict\": model.base.state_dict(),}, \"pretrained_model_4layers_no_class_head.pt\")"
      ],
      "execution_count": 191,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-xclMCpnVpw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f933fa99-0e31-475a-878a-a6f541bb10fa"
      },
      "source": [
        "from_scratch_settings = [True, False]\n",
        "\n",
        "from_scratch_valid_acc = []\n",
        "pretrained_valid_acc = []\n",
        "lr = 0.0001\n",
        "\n",
        "for from_scratch in from_scratch_settings:\n",
        "    model = Model(ntokens, nhead, nhid, nlayers, 2, dropout).to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    if not from_scratch:\n",
        "        print(\"=====PRETRAINED MODEL======\")\n",
        "        #load checkpoint\n",
        "        checkpoint = torch.load(\"pretrained_model_4layers_no_class_head.pt\")\n",
        "        #load state dict\n",
        "        model.base.load_state_dict(checkpoint['model_state_dict'])\n",
        "    else:\n",
        "        print(\"=====Trainig FROM SCRATCH======\")\n",
        "    epochs = 30\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        train(\n",
        "            path_data_train,\n",
        "            path_labels_train,\n",
        "            save_interval=-1,\n",
        "            task='classification',\n",
        "            batch_size=8,\n",
        "            log_interval=50,\n",
        "        )\n",
        "        acc = evaluate_accuracy(\n",
        "            get_loader(\n",
        "                path_data_valid,\n",
        "                path_labels_valid,\n",
        "                token2ind=token2ind,\n",
        "                batch_size=20,\n",
        "                task='classification',\n",
        "            )\n",
        "        )\n",
        "        if from_scratch:\n",
        "            from_scratch_valid_acc.append(acc)\n",
        "        else:\n",
        "            pretrained_valid_acc.append(acc)\n",
        "    print()"
      ],
      "execution_count": 216,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=====Trainig FROM SCRATCH======\n",
            "| epoch   1 |    50/  200 steps | loss 0.82335 | ppl    2.278\n",
            "| epoch   1 |   100/  200 steps | loss 0.78218 | ppl    2.186\n",
            "| epoch   1 |   150/  200 steps | loss 0.75907 | ppl    2.136\n",
            "your accuracy is  0.519\n",
            "| epoch   2 |    50/  200 steps | loss 0.76976 | ppl    2.159\n",
            "| epoch   2 |   100/  200 steps | loss 0.76490 | ppl    2.149\n",
            "| epoch   2 |   150/  200 steps | loss 0.74643 | ppl    2.109\n",
            "your accuracy is  0.4925\n",
            "| epoch   3 |    50/  200 steps | loss 0.76834 | ppl    2.156\n",
            "| epoch   3 |   100/  200 steps | loss 0.73360 | ppl    2.083\n",
            "| epoch   3 |   150/  200 steps | loss 0.73987 | ppl    2.096\n",
            "your accuracy is  0.519\n",
            "| epoch   4 |    50/  200 steps | loss 0.73472 | ppl    2.085\n",
            "| epoch   4 |   100/  200 steps | loss 0.71131 | ppl    2.037\n",
            "| epoch   4 |   150/  200 steps | loss 0.67662 | ppl    1.967\n",
            "your accuracy is  0.585\n",
            "| epoch   5 |    50/  200 steps | loss 0.64950 | ppl    1.915\n",
            "| epoch   5 |   100/  200 steps | loss 0.59510 | ppl    1.813\n",
            "| epoch   5 |   150/  200 steps | loss 0.62314 | ppl    1.865\n",
            "your accuracy is  0.651\n",
            "| epoch   6 |    50/  200 steps | loss 0.45698 | ppl    1.579\n",
            "| epoch   6 |   100/  200 steps | loss 0.52434 | ppl    1.689\n",
            "| epoch   6 |   150/  200 steps | loss 0.51911 | ppl    1.681\n",
            "your accuracy is  0.6995\n",
            "| epoch   7 |    50/  200 steps | loss 0.34362 | ppl    1.410\n",
            "| epoch   7 |   100/  200 steps | loss 0.39630 | ppl    1.486\n",
            "| epoch   7 |   150/  200 steps | loss 0.32587 | ppl    1.385\n",
            "your accuracy is  0.7015\n",
            "| epoch   8 |    50/  200 steps | loss 0.28441 | ppl    1.329\n",
            "| epoch   8 |   100/  200 steps | loss 0.27228 | ppl    1.313\n",
            "| epoch   8 |   150/  200 steps | loss 0.25402 | ppl    1.289\n",
            "your accuracy is  0.6985\n",
            "| epoch   9 |    50/  200 steps | loss 0.21126 | ppl    1.235\n",
            "| epoch   9 |   100/  200 steps | loss 0.23263 | ppl    1.262\n",
            "| epoch   9 |   150/  200 steps | loss 0.26944 | ppl    1.309\n",
            "your accuracy is  0.7035\n",
            "| epoch  10 |    50/  200 steps | loss 0.14921 | ppl    1.161\n",
            "| epoch  10 |   100/  200 steps | loss 0.26459 | ppl    1.303\n",
            "| epoch  10 |   150/  200 steps | loss 0.19207 | ppl    1.212\n",
            "your accuracy is  0.743\n",
            "| epoch  11 |    50/  200 steps | loss 0.13011 | ppl    1.139\n",
            "| epoch  11 |   100/  200 steps | loss 0.09248 | ppl    1.097\n",
            "| epoch  11 |   150/  200 steps | loss 0.11209 | ppl    1.119\n",
            "your accuracy is  0.729\n",
            "| epoch  12 |    50/  200 steps | loss 0.21079 | ppl    1.235\n",
            "| epoch  12 |   100/  200 steps | loss 0.10807 | ppl    1.114\n",
            "| epoch  12 |   150/  200 steps | loss 0.18210 | ppl    1.200\n",
            "your accuracy is  0.7405\n",
            "| epoch  13 |    50/  200 steps | loss 0.15468 | ppl    1.167\n",
            "| epoch  13 |   100/  200 steps | loss 0.11201 | ppl    1.119\n",
            "| epoch  13 |   150/  200 steps | loss 0.12082 | ppl    1.128\n",
            "your accuracy is  0.7215\n",
            "| epoch  14 |    50/  200 steps | loss 0.09121 | ppl    1.096\n",
            "| epoch  14 |   100/  200 steps | loss 0.17219 | ppl    1.188\n",
            "| epoch  14 |   150/  200 steps | loss 0.07888 | ppl    1.082\n",
            "your accuracy is  0.7475\n",
            "| epoch  15 |    50/  200 steps | loss 0.07645 | ppl    1.079\n",
            "| epoch  15 |   100/  200 steps | loss 0.10520 | ppl    1.111\n",
            "| epoch  15 |   150/  200 steps | loss 0.07394 | ppl    1.077\n",
            "your accuracy is  0.746\n",
            "| epoch  16 |    50/  200 steps | loss 0.05347 | ppl    1.055\n",
            "| epoch  16 |   100/  200 steps | loss 0.06664 | ppl    1.069\n",
            "| epoch  16 |   150/  200 steps | loss 0.05180 | ppl    1.053\n",
            "your accuracy is  0.746\n",
            "| epoch  17 |    50/  200 steps | loss 0.06262 | ppl    1.065\n",
            "| epoch  17 |   100/  200 steps | loss 0.05747 | ppl    1.059\n",
            "| epoch  17 |   150/  200 steps | loss 0.08783 | ppl    1.092\n",
            "your accuracy is  0.7485\n",
            "| epoch  18 |    50/  200 steps | loss 0.11005 | ppl    1.116\n",
            "| epoch  18 |   100/  200 steps | loss 0.05008 | ppl    1.051\n",
            "| epoch  18 |   150/  200 steps | loss 0.09064 | ppl    1.095\n",
            "your accuracy is  0.7475\n",
            "| epoch  19 |    50/  200 steps | loss 0.05872 | ppl    1.060\n",
            "| epoch  19 |   100/  200 steps | loss 0.07123 | ppl    1.074\n",
            "| epoch  19 |   150/  200 steps | loss 0.04904 | ppl    1.050\n",
            "your accuracy is  0.7455\n",
            "| epoch  20 |    50/  200 steps | loss 0.07764 | ppl    1.081\n",
            "| epoch  20 |   100/  200 steps | loss 0.07312 | ppl    1.076\n",
            "| epoch  20 |   150/  200 steps | loss 0.06743 | ppl    1.070\n",
            "your accuracy is  0.742\n",
            "| epoch  21 |    50/  200 steps | loss 0.05936 | ppl    1.061\n",
            "| epoch  21 |   100/  200 steps | loss 0.04859 | ppl    1.050\n",
            "| epoch  21 |   150/  200 steps | loss 0.05829 | ppl    1.060\n",
            "your accuracy is  0.742\n",
            "| epoch  22 |    50/  200 steps | loss 0.08907 | ppl    1.093\n",
            "| epoch  22 |   100/  200 steps | loss 0.09012 | ppl    1.094\n",
            "| epoch  22 |   150/  200 steps | loss 0.03248 | ppl    1.033\n",
            "your accuracy is  0.719\n",
            "| epoch  23 |    50/  200 steps | loss 0.07784 | ppl    1.081\n",
            "| epoch  23 |   100/  200 steps | loss 0.02990 | ppl    1.030\n",
            "| epoch  23 |   150/  200 steps | loss 0.10152 | ppl    1.107\n",
            "your accuracy is  0.7465\n",
            "| epoch  24 |    50/  200 steps | loss 0.03523 | ppl    1.036\n",
            "| epoch  24 |   100/  200 steps | loss 0.03441 | ppl    1.035\n",
            "| epoch  24 |   150/  200 steps | loss 0.02466 | ppl    1.025\n",
            "your accuracy is  0.75\n",
            "| epoch  25 |    50/  200 steps | loss 0.02018 | ppl    1.020\n",
            "| epoch  25 |   100/  200 steps | loss 0.02436 | ppl    1.025\n",
            "| epoch  25 |   150/  200 steps | loss 0.06921 | ppl    1.072\n",
            "your accuracy is  0.7515\n",
            "| epoch  26 |    50/  200 steps | loss 0.06773 | ppl    1.070\n",
            "| epoch  26 |   100/  200 steps | loss 0.01549 | ppl    1.016\n",
            "| epoch  26 |   150/  200 steps | loss 0.04322 | ppl    1.044\n",
            "your accuracy is  0.761\n",
            "| epoch  27 |    50/  200 steps | loss 0.01036 | ppl    1.010\n",
            "| epoch  27 |   100/  200 steps | loss 0.03849 | ppl    1.039\n",
            "| epoch  27 |   150/  200 steps | loss 0.00043 | ppl    1.000\n",
            "your accuracy is  0.7405\n",
            "| epoch  28 |    50/  200 steps | loss 0.04574 | ppl    1.047\n",
            "| epoch  28 |   100/  200 steps | loss 0.06324 | ppl    1.065\n",
            "| epoch  28 |   150/  200 steps | loss 0.01522 | ppl    1.015\n",
            "your accuracy is  0.7345\n",
            "| epoch  29 |    50/  200 steps | loss 0.01148 | ppl    1.012\n",
            "| epoch  29 |   100/  200 steps | loss 0.00869 | ppl    1.009\n",
            "| epoch  29 |   150/  200 steps | loss 0.03369 | ppl    1.034\n",
            "your accuracy is  0.76\n",
            "| epoch  30 |    50/  200 steps | loss 0.07110 | ppl    1.074\n",
            "| epoch  30 |   100/  200 steps | loss 0.00057 | ppl    1.001\n",
            "| epoch  30 |   150/  200 steps | loss 0.02116 | ppl    1.021\n",
            "your accuracy is  0.7485\n",
            "\n",
            "=====PRETRAINED MODEL======\n",
            "| epoch   1 |    50/  200 steps | loss 0.88205 | ppl    2.416\n",
            "| epoch   1 |   100/  200 steps | loss 0.77201 | ppl    2.164\n",
            "| epoch   1 |   150/  200 steps | loss 0.76221 | ppl    2.143\n",
            "your accuracy is  0.6045\n",
            "| epoch   2 |    50/  200 steps | loss 0.79911 | ppl    2.224\n",
            "| epoch   2 |   100/  200 steps | loss 0.63545 | ppl    1.888\n",
            "| epoch   2 |   150/  200 steps | loss 0.59961 | ppl    1.821\n",
            "your accuracy is  0.7035\n",
            "| epoch   3 |    50/  200 steps | loss 0.59705 | ppl    1.817\n",
            "| epoch   3 |   100/  200 steps | loss 0.57111 | ppl    1.770\n",
            "| epoch   3 |   150/  200 steps | loss 0.55628 | ppl    1.744\n",
            "your accuracy is  0.739\n",
            "| epoch   4 |    50/  200 steps | loss 0.50304 | ppl    1.654\n",
            "| epoch   4 |   100/  200 steps | loss 0.51345 | ppl    1.671\n",
            "| epoch   4 |   150/  200 steps | loss 0.49148 | ppl    1.635\n",
            "your accuracy is  0.7125\n",
            "| epoch   5 |    50/  200 steps | loss 0.49140 | ppl    1.635\n",
            "| epoch   5 |   100/  200 steps | loss 0.50543 | ppl    1.658\n",
            "| epoch   5 |   150/  200 steps | loss 0.52140 | ppl    1.684\n",
            "your accuracy is  0.7625\n",
            "| epoch   6 |    50/  200 steps | loss 0.45592 | ppl    1.578\n",
            "| epoch   6 |   100/  200 steps | loss 0.50369 | ppl    1.655\n",
            "| epoch   6 |   150/  200 steps | loss 0.43485 | ppl    1.545\n",
            "your accuracy is  0.7545\n",
            "| epoch   7 |    50/  200 steps | loss 0.44957 | ppl    1.568\n",
            "| epoch   7 |   100/  200 steps | loss 0.37853 | ppl    1.460\n",
            "| epoch   7 |   150/  200 steps | loss 0.46187 | ppl    1.587\n",
            "your accuracy is  0.762\n",
            "| epoch   8 |    50/  200 steps | loss 0.38875 | ppl    1.475\n",
            "| epoch   8 |   100/  200 steps | loss 0.42807 | ppl    1.534\n",
            "| epoch   8 |   150/  200 steps | loss 0.48444 | ppl    1.623\n",
            "your accuracy is  0.7505\n",
            "| epoch   9 |    50/  200 steps | loss 0.35293 | ppl    1.423\n",
            "| epoch   9 |   100/  200 steps | loss 0.43629 | ppl    1.547\n",
            "| epoch   9 |   150/  200 steps | loss 0.40767 | ppl    1.503\n",
            "your accuracy is  0.7595\n",
            "| epoch  10 |    50/  200 steps | loss 0.38514 | ppl    1.470\n",
            "| epoch  10 |   100/  200 steps | loss 0.36664 | ppl    1.443\n",
            "| epoch  10 |   150/  200 steps | loss 0.44526 | ppl    1.561\n",
            "your accuracy is  0.7785\n",
            "| epoch  11 |    50/  200 steps | loss 0.36414 | ppl    1.439\n",
            "| epoch  11 |   100/  200 steps | loss 0.35886 | ppl    1.432\n",
            "| epoch  11 |   150/  200 steps | loss 0.32003 | ppl    1.377\n",
            "your accuracy is  0.769\n",
            "| epoch  12 |    50/  200 steps | loss 0.42789 | ppl    1.534\n",
            "| epoch  12 |   100/  200 steps | loss 0.29918 | ppl    1.349\n",
            "| epoch  12 |   150/  200 steps | loss 0.25013 | ppl    1.284\n",
            "your accuracy is  0.7925\n",
            "| epoch  13 |    50/  200 steps | loss 0.35577 | ppl    1.427\n",
            "| epoch  13 |   100/  200 steps | loss 0.34818 | ppl    1.416\n",
            "| epoch  13 |   150/  200 steps | loss 0.37157 | ppl    1.450\n",
            "your accuracy is  0.79\n",
            "| epoch  14 |    50/  200 steps | loss 0.35854 | ppl    1.431\n",
            "| epoch  14 |   100/  200 steps | loss 0.31013 | ppl    1.364\n",
            "| epoch  14 |   150/  200 steps | loss 0.29627 | ppl    1.345\n",
            "your accuracy is  0.782\n",
            "| epoch  15 |    50/  200 steps | loss 0.27664 | ppl    1.319\n",
            "| epoch  15 |   100/  200 steps | loss 0.21563 | ppl    1.241\n",
            "| epoch  15 |   150/  200 steps | loss 0.32081 | ppl    1.378\n",
            "your accuracy is  0.786\n",
            "| epoch  16 |    50/  200 steps | loss 0.33842 | ppl    1.403\n",
            "| epoch  16 |   100/  200 steps | loss 0.29818 | ppl    1.347\n",
            "| epoch  16 |   150/  200 steps | loss 0.27756 | ppl    1.320\n",
            "your accuracy is  0.789\n",
            "| epoch  17 |    50/  200 steps | loss 0.33110 | ppl    1.393\n",
            "| epoch  17 |   100/  200 steps | loss 0.32324 | ppl    1.382\n",
            "| epoch  17 |   150/  200 steps | loss 0.30730 | ppl    1.360\n",
            "your accuracy is  0.785\n",
            "| epoch  18 |    50/  200 steps | loss 0.17409 | ppl    1.190\n",
            "| epoch  18 |   100/  200 steps | loss 0.20483 | ppl    1.227\n",
            "| epoch  18 |   150/  200 steps | loss 0.28882 | ppl    1.335\n",
            "your accuracy is  0.7805\n",
            "| epoch  19 |    50/  200 steps | loss 0.24035 | ppl    1.272\n",
            "| epoch  19 |   100/  200 steps | loss 0.31922 | ppl    1.376\n",
            "| epoch  19 |   150/  200 steps | loss 0.23212 | ppl    1.261\n",
            "your accuracy is  0.779\n",
            "| epoch  20 |    50/  200 steps | loss 0.17679 | ppl    1.193\n",
            "| epoch  20 |   100/  200 steps | loss 0.21336 | ppl    1.238\n",
            "| epoch  20 |   150/  200 steps | loss 0.23202 | ppl    1.261\n",
            "your accuracy is  0.7795\n",
            "| epoch  21 |    50/  200 steps | loss 0.21844 | ppl    1.244\n",
            "| epoch  21 |   100/  200 steps | loss 0.26083 | ppl    1.298\n",
            "| epoch  21 |   150/  200 steps | loss 0.21586 | ppl    1.241\n",
            "your accuracy is  0.774\n",
            "| epoch  22 |    50/  200 steps | loss 0.22973 | ppl    1.258\n",
            "| epoch  22 |   100/  200 steps | loss 0.26275 | ppl    1.301\n",
            "| epoch  22 |   150/  200 steps | loss 0.25937 | ppl    1.296\n",
            "your accuracy is  0.772\n",
            "| epoch  23 |    50/  200 steps | loss 0.15604 | ppl    1.169\n",
            "| epoch  23 |   100/  200 steps | loss 0.18876 | ppl    1.208\n",
            "| epoch  23 |   150/  200 steps | loss 0.21779 | ppl    1.243\n",
            "your accuracy is  0.778\n",
            "| epoch  24 |    50/  200 steps | loss 0.21009 | ppl    1.234\n",
            "| epoch  24 |   100/  200 steps | loss 0.28298 | ppl    1.327\n",
            "| epoch  24 |   150/  200 steps | loss 0.17301 | ppl    1.189\n",
            "your accuracy is  0.773\n",
            "| epoch  25 |    50/  200 steps | loss 0.19954 | ppl    1.221\n",
            "| epoch  25 |   100/  200 steps | loss 0.18297 | ppl    1.201\n",
            "| epoch  25 |   150/  200 steps | loss 0.23684 | ppl    1.267\n",
            "your accuracy is  0.792\n",
            "| epoch  26 |    50/  200 steps | loss 0.15898 | ppl    1.172\n",
            "| epoch  26 |   100/  200 steps | loss 0.17983 | ppl    1.197\n",
            "| epoch  26 |   150/  200 steps | loss 0.17369 | ppl    1.190\n",
            "your accuracy is  0.785\n",
            "| epoch  27 |    50/  200 steps | loss 0.22325 | ppl    1.250\n",
            "| epoch  27 |   100/  200 steps | loss 0.22916 | ppl    1.258\n",
            "| epoch  27 |   150/  200 steps | loss 0.13546 | ppl    1.145\n",
            "your accuracy is  0.7865\n",
            "| epoch  28 |    50/  200 steps | loss 0.08854 | ppl    1.093\n",
            "| epoch  28 |   100/  200 steps | loss 0.17032 | ppl    1.186\n",
            "| epoch  28 |   150/  200 steps | loss 0.13034 | ppl    1.139\n",
            "your accuracy is  0.795\n",
            "| epoch  29 |    50/  200 steps | loss 0.15681 | ppl    1.170\n",
            "| epoch  29 |   100/  200 steps | loss 0.08570 | ppl    1.089\n",
            "| epoch  29 |   150/  200 steps | loss 0.18249 | ppl    1.200\n",
            "your accuracy is  0.772\n",
            "| epoch  30 |    50/  200 steps | loss 0.17637 | ppl    1.193\n",
            "| epoch  30 |   100/  200 steps | loss 0.09317 | ppl    1.098\n",
            "| epoch  30 |   150/  200 steps | loss 0.28176 | ppl    1.325\n",
            "your accuracy is  0.786\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCpBIdTHojm6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "617204f3-3319-419f-8937-d201c3784529"
      },
      "source": [
        "#Visualize the accuracy\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(from_scratch_valid_acc,label=\"from scratch\")\n",
        "plt.plot(pretrained_valid_acc,label='pretrained')\n",
        "\n",
        "plt.plot()\n",
        "plt.legend()\n"
      ],
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fb5f15fd2b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 217
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}